{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqfsBnIIQytn",
        "outputId": "727311e2-284f-4482-e4e8-1ae8ab57df95"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running CIFAR-10 Dense Baseline...\n",
            "Running CIFAR-10 Dense vs Sparse Comparison...\n",
            "1. Running Dense Baseline on CIFAR-10...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 39.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Epoch   1: Train: 18.37%, Val: 24.45%\n",
            "Dense Epoch  21: Train: 75.77%, Val: 72.60%\n",
            "Dense Epoch  41: Train: 79.97%, Val: 74.47%\n",
            "Dense Epoch  61: Train: 81.60%, Val: 77.78%\n",
            "Dense Epoch  81: Train: 83.86%, Val: 76.69%\n",
            "Dense Epoch 101: Train: 85.86%, Val: 81.27%\n",
            "Dense Epoch 121: Train: 88.27%, Val: 81.67%\n",
            "Dense Epoch 141: Train: 91.10%, Val: 86.07%\n",
            "Dense Epoch 161: Train: 94.52%, Val: 89.44%\n",
            "Dense Epoch 181: Train: 97.36%, Val: 91.36%\n",
            "Dense Epoch 200: Train: 98.15%, Val: 91.60%\n",
            "\n",
            "Dense CIFAR-10 training completed: 95.27% test accuracy in 3221.6s\n",
            "\n",
            "============================================================\n",
            "CIFAR-10: DENSE vs SPARSE COMPARISON\n",
            "============================================================\n",
            "Dense Baseline:      95.27% (11.2M parameters)\n",
            "Dynamic Pruning:     95.19 ± 0.11% (~2.3M parameters)\n",
            "Accuracy difference: -0.08 percentage points\n",
            "Parameter reduction: 79.6% (~8.9M parameters removed)\n",
            "\n",
            "Training Time:\n",
            "Dense:               3221.6s\n",
            "Dynamic Pruning:     ~3553s (from your results)\n",
            "\n",
            "CIFAR-10 Efficiency Summary:\n",
            "• Achieved 79.6% parameter reduction\n",
            "• Accuracy performance: -0.08 percentage points vs dense\n",
            "• Single training cycle with progressive sparsification\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Use the same ResNet architecture from your sparse code\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Dense ResNet (same as your sparse version but without masking)\n",
        "class DenseResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(DenseResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        layers = []\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        for s in strides:\n",
        "            layers.append(block(self.in_planes, planes, s))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def DenseResNet18(num_classes=10):\n",
        "    return DenseResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "def initialize_weights_dense(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.ones_(m.weight)\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "def evaluate_dense(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    loss_total = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss_total += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = loss_total / total\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_cifar10_dense_baseline(epochs=200, device='cuda', seed=42):\n",
        "    \"\"\"Dense baseline with IDENTICAL setup to your sparse training\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Use your EXACT same data transforms\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomErasing(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "\n",
        "    # Use your EXACT same dataset split\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform_train\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform_test\n",
        "    )\n",
        "\n",
        "    train_size = int(0.89 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_subset, val_subset = torch.utils.data.random_split(\n",
        "        train_dataset, [train_size, val_size]\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_subset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_subset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Use your EXACT same model architecture (without masking)\n",
        "    model = DenseResNet18(num_classes=10).to(device)\n",
        "\n",
        "    # Use your EXACT same training setup\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4\n",
        "    )\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    # Use your EXACT same initialization\n",
        "    initialize_weights_dense(model)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if epoch % 20 == 0 or epoch == epochs - 1:\n",
        "            val_loss, val_accuracy = evaluate_dense(model, val_loader, criterion, device)\n",
        "            train_accuracy = 100.0 * correct / total\n",
        "            print(f\"Dense Epoch {epoch+1:3d}: Train: {train_accuracy:.2f}%, Val: {val_accuracy:.2f}%\")\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    test_loss, test_accuracy = evaluate_dense(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"\\nDense CIFAR-10 training completed: {test_accuracy:.2f}% test accuracy in {training_time:.1f}s\")\n",
        "\n",
        "    return {\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'training_time': training_time,\n",
        "        'final_sparsity': 0.0\n",
        "    }\n",
        "\n",
        "def run_cifar10_comparison():\n",
        "    \"\"\"Compare your sparse results with dense baseline\"\"\"\n",
        "\n",
        "    print(\"Running CIFAR-10 Dense vs Sparse Comparison...\")\n",
        "    print(\"1. Running Dense Baseline on CIFAR-10...\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dense_result = train_cifar10_dense_baseline(epochs=200, device=device, seed=42)\n",
        "\n",
        "    # Your sparse results (from your code output)\n",
        "    sparse_accuracy = 95.19\n",
        "    sparse_std = 0.11\n",
        "    sparse_sparsity = 79.6\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CIFAR-10: DENSE vs SPARSE COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Dense Baseline:      {dense_result['test_accuracy']:.2f}% (11.2M parameters)\")\n",
        "    print(f\"Dynamic Pruning:     {sparse_accuracy:.2f} ± {sparse_std:.2f}% (~2.3M parameters)\")\n",
        "    print(f\"Accuracy difference: {sparse_accuracy - dense_result['test_accuracy']:+.2f} percentage points\")\n",
        "    print(f\"Parameter reduction: {sparse_sparsity:.1f}% (~8.9M parameters removed)\")\n",
        "\n",
        "    print(f\"\\nTraining Time:\")\n",
        "    print(f\"Dense:               {dense_result['training_time']:.1f}s\")\n",
        "    print(f\"Dynamic Pruning:     ~3553s (from your results)\")\n",
        "\n",
        "    accuracy_diff = sparse_accuracy - dense_result['test_accuracy']\n",
        "    print(f\"\\nCIFAR-10 Efficiency Summary:\")\n",
        "    print(f\"• Achieved {sparse_sparsity:.1f}% parameter reduction\")\n",
        "    print(f\"• Accuracy performance: {accuracy_diff:+.2f} percentage points vs dense\")\n",
        "    print(f\"• Single training cycle with progressive sparsification\")\n",
        "\n",
        "    return dense_result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Running CIFAR-10 Dense Baseline...\")\n",
        "    result = run_cifar10_comparison()"
      ]
    }
  ]
}